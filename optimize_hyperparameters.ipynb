{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "In this section all required libraries are imported"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from geneticalgorithm import geneticalgorithm as ga\n",
    "import csv\n",
    "import pandas as pd\n",
    "from keras.utils import np_utils\n",
    "from sklearn import metrics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.optimizers import SGD,Adam\n",
    "from keras.models import Model\n",
    "from keras import layers\n",
    "import keras\n",
    "import sklearn.model_selection\n",
    "from keras.initializers import RandomUniform\n",
    "from keras import backend as back"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing\n",
    "\n",
    "Preprocessing including 4 steps:\n",
    "1_ Normalization: Because the minimum and maximum of EMG signal is known, so the best method for normalization is minmax method. After normalization all data placed between -1 and +1.\n",
    "2_ Windowing: For increasing the number of data and preparing them in order to feed them to model, windowing is crucial. Also, the length and shape of window and overlapping between consecutive windows are essential factors that cause variation in the accuracy of model. The length of window is an important factor that determines usecase of network for online and offline recognition.\n",
    "3_ Splitting data into train, validation and test set with the rate of 70, 15 and 15 percent. Also, test data has not be seen by model before.\n",
    "4_ Preparing target: The last layer of model in comprised of softmax layer. Therefor we need to transform labels into onehot form."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#Data preprocessing with 16 channels and N samples\n",
    "def mode_rows(a):\n",
    "    a = np.ascontiguousarray(a)\n",
    "    void_dt = np.dtype((np.void, a.dtype.itemsize * np.prod(a.shape[1:])))\n",
    "    _,ids, count = np.unique(a.view(void_dt).ravel(), \\\n",
    "                                return_index=1,return_counts=1)\n",
    "    largest_count_id = ids[count.argmax()]\n",
    "    most_frequent_row = a[largest_count_id]\n",
    "    return most_frequent_row\n",
    "\n",
    "#import data from dataset file\n",
    "a = pd.read_pickle(r'/content/dualmyo_dataset.pkl')\n",
    "signal_list =a[0]\n",
    "label_list =a[1]\n",
    "\n",
    "signal = np.array([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "k = 0\n",
    "coef = np.ones([400,1])\n",
    "target = np.array([0])\n",
    "\n",
    "#windowing the signal\n",
    "for s in signal_list :\n",
    "  signal1 = np.hstack([abs(s[:,2:10]),abs(s[:,12:20])])\n",
    "  signal = np.vstack((signal,signal1))\n",
    "  target = np.vstack((target,label_list[k]*coef))\n",
    "  k = k + 1\n",
    "\n",
    "print(signal.shape)\n",
    "print(target.shape)\n",
    "\n",
    "data = np.concatenate((signal,target),axis=1)\n",
    "\n",
    "seq_len = 200\n",
    "stride = 200\n",
    "dataset=[]\n",
    "\n",
    "for i in range(0 , len(data)-seq_len , stride):\n",
    "    sample =  data[i:i+seq_len,:]\n",
    "    dataset.append(sample)\n",
    "\n",
    "#Splitting data into train and test sets\n",
    "#np.random.shuffle(dataset)\n",
    "train, test = sklearn.model_selection.train_test_split(dataset , train_size =int( np.round(0.85*len(dataset))) , test_size = int(np.round(0.15*len(dataset))), shuffle = False)\n",
    "\n",
    "\n",
    "x_train = np.zeros([len(train),seq_len,16,1])\n",
    "y_train = np.zeros([len(train),1])\n",
    "f=0\n",
    "for s  in train :\n",
    "    x_train[f,:,:,:] = s[:,0:16].reshape(-1,16,1)\n",
    "    y_train[f, 0] = mode_rows(s[seq_len-20:seq_len,16])\n",
    "    f = f+1\n",
    "#Normalizing input data and transforming output to onehot for train data\n",
    "x_tra = (x_train/128).astype('float32')\n",
    "y_tra = np_utils.to_categorical(y_train)\n",
    "\n",
    "\n",
    "\n",
    "x_test = np.zeros([len(test),seq_len,16,1])\n",
    "y_test = np.zeros([len(test),1])\n",
    "p=0\n",
    "for s  in test :\n",
    "    x_test[p,:,:,:] = s[:,0:16].reshape(-1,16,1)\n",
    "    y_test[p, 0] = mode_rows(s[seq_len-20:seq_len,16])\n",
    "    p = p+1\n",
    "#Normalizing input data and transforming output to onehot for test data\n",
    "x_tes = (x_test/128).astype('float32')\n",
    "y_tes = np_utils.to_categorical(y_test)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Define function which create model with various hyper-parameters:\n",
    "The output of this function is considered as cost function of genetic algorithm. Genetic algorithm tries to minimize the cost function. So, we use the minus of accuracy of model as cost function."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "noi=0\n",
    "pp={}\n",
    "def f(XX):\n",
    "    global noi\n",
    "    noi = noi+1\n",
    "    v = tuple(map(tuple,[XX]))\n",
    "    if v in pp:\n",
    "        return(pp[v])\n",
    "    else:\n",
    "        a=int(XX[0])\n",
    "        print((XX[0]))\n",
    "\n",
    "        b=int(XX[1])\n",
    "        print((XX[1]))\n",
    "\n",
    "        c=int(XX[2])\n",
    "        print((XX[2]))\n",
    "\n",
    "        d=int(XX[3])\n",
    "        print((XX[3]))\n",
    "\n",
    "        e=int(XX[4])\n",
    "        print((XX[4]))\n",
    "\n",
    "        f=int(XX[5])\n",
    "        print((XX[5]))\n",
    "\n",
    "        c1 = int(XX[6])\n",
    "        print(XX[6])\n",
    "        c2 = int(XX[7])\n",
    "        print(XX[7])\n",
    "\n",
    "        d1 = int(XX[8])\n",
    "        print(XX[8])\n",
    "        d2 = int(XX[9])\n",
    "        print(XX[9])\n",
    "\n",
    "        e1 = int(XX[10])\n",
    "        print(XX[10])\n",
    "        e2 = int(XX[11])\n",
    "        print(XX[11])\n",
    "\n",
    "        f1 = int(XX[12])\n",
    "        print(XX[12])\n",
    "        f2 = int(XX[13])\n",
    "        print(XX[13])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if a == 1:\n",
    "\n",
    "            myInput = layers.Input(shape=(seq_len,16,1))\n",
    "            conv1 = layers.Conv2D(c, (c1,c2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(myInput)\n",
    "            flat = layers.Flatten()(conv1)\n",
    "            dense1 = layers.Dense(b, activation='relu',kernel_initializer=RandomUniform())(flat)\n",
    "            out_layer = layers.Dense(8, activation='softmax',kernel_initializer=RandomUniform())(dense1)\n",
    "\n",
    "        elif a==2:\n",
    "\n",
    "            myInput = layers.Input(shape=(seq_len,16,1))\n",
    "            conv1 = layers.Conv2D(c, (c1,c2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(myInput)\n",
    "            conv2 = layers.Conv2D(d, (d1,d2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(conv1)\n",
    "            flat = layers.Flatten()(conv2)\n",
    "            dense1 = layers.Dense(b, activation='relu',kernel_initializer=RandomUniform())(flat)\n",
    "            out_layer = layers.Dense(8, activation='softmax',kernel_initializer=RandomUniform())(dense1)\n",
    "\n",
    "        elif a==3:\n",
    "\n",
    "            myInput = layers.Input(shape=(seq_len,16,1))\n",
    "            conv1 = layers.Conv2D(c, (c1,c2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(myInput)\n",
    "            conv2 = layers.Conv2D(d, (d1,d2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(conv1)\n",
    "            conv3 = layers.Conv2D(e, (e1,e2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(conv2)\n",
    "            flat = layers.Flatten()(conv3)\n",
    "            dense1 = layers.Dense(b, activation='relu',kernel_initializer=RandomUniform())(flat)\n",
    "            out_layer = layers.Dense(8, activation='softmax',kernel_initializer=RandomUniform())(dense1)\n",
    "\n",
    "        elif a==4:\n",
    "\n",
    "            myInput = layers.Input(shape=(seq_len,16,1))\n",
    "            conv1 = layers.Conv2D(c, (c1,c2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(myInput)\n",
    "            conv2 = layers.Conv2D(d, (d1,d2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(conv1)\n",
    "            conv3 = layers.Conv2D(e, (e1,e2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(conv2)\n",
    "            conv4 = layers.Conv2D(f, (f1,f2), activation='relu',kernel_initializer=RandomUniform(), padding='same', strides=1)(conv3)\n",
    "            flat = layers.Flatten()(conv4)\n",
    "            dense1 = layers.Dense(b, activation='relu',kernel_initializer=RandomUniform())(flat)\n",
    "            out_layer = layers.Dense(8, activation='softmax',kernel_initializer=RandomUniform())(dense1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        model = Model(myInput, out_layer)\n",
    "\n",
    "        #Compilie\n",
    "        model.compile( optimizer=Adam (lr=0.001 ) , loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "\n",
    "\n",
    "        #model fit\n",
    "        model.fit(x_tra , y_tra, epochs=15 , batch_size=64 ,shuffle=True , validation_split=0.15)\n",
    "\n",
    "        #model evaluation\n",
    "        test_loss, test_acc = model.evaluate(x_tes, y_tes)\n",
    "        back.clear_session()\n",
    "        pp[v] = -test_acc\n",
    "\n",
    "        return(-test_acc)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define genetic algorithm\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "varbound = np.array([[1, 4 ],[1, 150],[1, 150],[1, 150],[1, 150],[1, 150],[1,64],[1,16],[1,64],[1,16],[1,64],[1,16],[1,64],[1,16]])\n",
    "vartype = np.array([['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int'],['int']])\n",
    "\n",
    "algorithm_param = {'max_num_iteration':5000 ,\\\n",
    "                   'population_size':42,\\\n",
    "                   'mutation_probability':0.1,\\\n",
    "                   'elit_ratio': 0.1,\\\n",
    "                   'crossover_probability': 0.2,\\\n",
    "                   'parents_portion': 0.3,\\\n",
    "                   'crossover_type':'uniform',\\\n",
    "                   'max_iteration_without_improv':5}\n",
    "gmodel = ga(function=f,dimension=14,variable_type_mixed=vartype,variable_boundaries=varbound,\n",
    "                              algorithm_parameters=algorithm_param,function_timeout = 720000)\n",
    "\n",
    "gmodel.run()\n",
    "convergence=gmodel.report\n",
    "output = gmodel.output_dict\n",
    "print('#####################################################')\n",
    "print(-(output['function']))\n",
    "print((output['variable']))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}